{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:02.177958Z",
     "start_time": "2025-04-16T10:09:01.065861Z"
    }
   },
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from enums import CollectionNames, EmbeddingModels\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "from retrieval_util import (\n",
    "    get_qdrant_client,\n",
    "    get_embeddings_function,\n",
    "    retrieve_with_score_without_filters\n",
    ")\n",
    "\n",
    "import os\n",
    "import re\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "os.environ[\n",
    "    \"TOKENIZERS_PARALLELISM\"] = \"false\"  # Verhindert Fehler beim Erzeugen von Embeddings (Tritt sporadisch auf, konnte nicht gezielt reproduziert werden)\n",
    "logging.basicConfig(level=logging.INFO)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Der Code ist nahezu identisch zu dem aus dem antworten_generieren.ipynb, jedoch werden hier 5 andere Fragen genutzt, deren Antworten nicht im Kontext enthalten sind.\n",
   "id": "29e93cd6d97712bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:11.814762Z",
     "start_time": "2025-04-16T10:09:04.366647Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Konstanten\n",
    "EMBEDDINGS = get_embeddings_function(model_name=EmbeddingModels.MIXEDBREAD.value)\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "COLLECTION = CollectionNames.MIXEDBREAD_RECURSIVE.value\n",
    "\n",
    "FRAGEN = {\n",
    "    1: \"Wer ist der Präsident der USA?\",\n",
    "    2: \"Wie funktioniert der HNSW Algorithmus?\",\n",
    "    3: \"Welche Algorithmen eignen sich für die Suche in Vektordatenbanken?\",\n",
    "    4: \"Ist die FH morgen geschlossen?\",\n",
    "    5: \"Welche Studiengänge werden an der Ruhr-Universität Bochum angeboten?\",\n",
    "}\n",
    "LLAMA_MODELL = \"llama3.1:8b\""
   ],
   "id": "ad47c16283b2f48f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bastian/Desktop/BachelorProjektAbgabe/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-04-16 12:09:08,173 [INFO] PyTorch version 2.6.0 available.\n",
      "2025-04-16 12:09:08,515 [INFO] Use pytorch device_name: mps\n",
      "2025-04-16 12:09:08,515 [INFO] Load pretrained SentenceTransformer: mixedbread-ai/deepset-mxbai-embed-de-large-v1\n",
      "2025-04-16 12:09:11,812 [INFO] 2 prompts are loaded, with the keys: ['query', 'passage']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:19.058174Z",
     "start_time": "2025-04-16T10:09:19.053963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "FH_PROMPT = \"\"\"\n",
    "<|begin_of_text|>\n",
    "<|start_header_id|>system<|end_header_id|>\n",
    "Du bist der Assistent der Fachhochschule Südwestfalen (FH-SWF).\n",
    "Du beantwortest Fragen von Studieninteressierten und Studierenden.\n",
    "\n",
    "Nutze den bereitgestellten Kontext, um die Frage konkret zu beantworten.\n",
    "Wenn du die Frage nicht aus dem Kontext beantworten kannst, antworte mit \"Das weiß ich leider nicht.\", sonst nichts.\n",
    "Erfinde niemals etwas, was nicht aus dem Kontext hervorgeht.\n",
    "\n",
    "<|start_header_id|>user<|end_header_id|>\n",
    "Kontext: {context}\n",
    "Frage: {query}\n",
    "\n",
    "<|start_header_id|>assistant<|end_header_id|>\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt_template = ChatPromptTemplate.from_template(FH_PROMPT)"
   ],
   "id": "2302044d28ba8bd4",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:21.883058Z",
     "start_time": "2025-04-16T10:09:21.840803Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LLAMA_LLM = ChatOllama(\n",
    "    model=LLAMA_MODELL,\n",
    "    temperature=0,\n",
    "    num_ctx=10000\n",
    "    # Kann später reduziert werden, je nachdem wie viel Speicher benötigt wird. Kontext (max. 10 * 504) + Frage + Prompt sollte nie mehr als ca. 8k Tokens haben\n",
    ")"
   ],
   "id": "a57934ed7a4ee8ae",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:23.575678Z",
     "start_time": "2025-04-16T10:09:23.267343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Kontexte formatieren vor der Übergabe an das LLM\n",
    "def keep_relevant_metadata(documents: list[Document]) -> Tuple[List[Document], List[str]]:\n",
    "    relevant_metadata = [\n",
    "        \"standort\",\n",
    "        \"studiengang\",\n",
    "        \"abschluss\"\n",
    "    ]\n",
    "    links = []\n",
    "    for doc in documents:\n",
    "        if doc.metadata['link'] not in links:\n",
    "            links.append(doc.metadata['link'])\n",
    "        doc.metadata = {key: doc.metadata[key] for key in relevant_metadata}\n",
    "    return documents, links\n",
    "\n",
    "\n",
    "def format_page_content(documents: list[Document]) -> str:\n",
    "    formatted_context = \"\"\n",
    "    for doc in documents:\n",
    "        formatted_context += f\"Standort: {doc.metadata['standort']}, Studiengang: {doc.metadata['studiengang']}, Abschluss: {doc.metadata['abschluss']}\\n{doc.page_content}\\n\\n\"\n",
    "    return formatted_context\n",
    "\n",
    "\n",
    "def prepare_context(retrieved_documents: list[Document]) -> Tuple[str, List[str]]:\n",
    "    documents, links = keep_relevant_metadata(retrieved_documents)\n",
    "    prepared_context = format_page_content(documents)\n",
    "    return prepared_context, links\n",
    "\n",
    "\n",
    "# Qdrant-Clinet mit mixedbread-ai/deepset-mxbai-embed-de-large-v1, Recursive Chunks\n",
    "best_client = get_qdrant_client(embeddings=EMBEDDINGS,\n",
    "                                collection_name=COLLECTION,\n",
    "                                qdrant_url=QDRANT_URL)"
   ],
   "id": "30626ef0a1de3112",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:09:23,323 [INFO] HTTP Request: GET http://localhost:6333 \"HTTP/1.1 200 OK\"\n",
      "2025-04-16 12:09:23,334 [INFO] HTTP Request: GET http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:09:28.836037Z",
     "start_time": "2025-04-16T10:09:28.833021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "LLAMA_ANSWERS_DIR = \"./antworten_llama_base_model_negative_rejection\"\n",
    "MAX_DOCUMENTS = 10"
   ],
   "id": "16729f2923a02425",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-16T10:11:39.214949Z",
     "start_time": "2025-04-16T10:09:33.002826Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for frage in FRAGEN.items():\n",
    "    frage_id, frage_text = frage\n",
    "    print(f\"Frage {frage_id}: {frage_text}\")\n",
    "    retrieved_documents = retrieve_with_score_without_filters(client=best_client,\n",
    "                                                           max_documents=MAX_DOCUMENTS,\n",
    "                                                           query=frage_text)\n",
    "    documents_only = [doc for doc, _ in retrieved_documents]\n",
    "    context, links = prepare_context(documents_only)\n",
    "    prompt = rag_prompt_template.invoke({\"context\": context, \"query\": frage_text})\n",
    "    response = LLAMA_LLM.invoke(prompt)\n",
    "    answer = response.content\n",
    "    input_tokens = response.usage_metadata[\"input_tokens\"]\n",
    "    print(f\"Input Tokens: {input_tokens}\")\n",
    "    print(f\"Antwort: {answer}\\n{'-' * 50}\")\n",
    "    print(\"Für weitere Informationen besuchen Sie:\")\n",
    "    for link in links[\n",
    "                :2]:  # Nur die ersten beiden Links anzeigen, da der MRR=0.911 ist, ist davon auszugehen, dass die relevanten Links in den ersten Positionen sind\n",
    "        print(f\"- {link}\")\n",
    "\n",
    "    clean_question_text = re.sub(r'[^\\w\\s-]', '', frage_text)\n",
    "    filename = f\"{frage_id}_{clean_question_text}.txt\"\n",
    "    filepath = os.path.join(LLAMA_ANSWERS_DIR, filename)\n",
    "\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(f\"Frage {frage_id}: {frage_text}\\n\\n\")\n",
    "        file.write(f\"Antwort:\\n{answer}\\n\\n\")"
   ],
   "id": "cd6305ddc959e725",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:09:33,164 [INFO] HTTP Request: POST http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks/points/query \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frage 1: Wer ist der Präsident der USA?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:09:44,178 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 1237\n",
      "Antwort: Das weiß ich leider nicht.\n",
      "--------------------------------------------------\n",
      "Für weitere Informationen besuchen Sie:\n",
      "- https://www.fh-swf.de/de/studienangebot/index.php\n",
      "- https://www.fh-swf.de/media/neu_np/hv_2/dateien_sg_2_4/verlaufsplaene_modulhandbuecher_1/soest_4/fb_eet_3/Modulhandbuch_BA_ETS_ETA_ETP_20_02.2024.pdf\n",
      "Frage 2: Wie funktioniert der HNSW Algorithmus?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:09:45,410 [INFO] HTTP Request: POST http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-04-16 12:10:07,879 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 4773\n",
      "Antwort: Das weiß ich leider nicht.\n",
      "--------------------------------------------------\n",
      "Für weitere Informationen besuchen Sie:\n",
      "- https://www.fh-swf.de/media/neu_np/hv_2/dateien_sg_2_4/verlaufsplaene_modulhandbuecher_1/hagen/tbw_neu/Modulhandbuch_Winf_FPO_2018_Stand_09.2024.pdf\n",
      "- https://www.fh-swf.de/media/neu_np/hv_2/dateien_sg_2_4/verlaufsplaene_modulhandbuecher_1/meschede_6/Modulhandbuch_BA_WFM_19_2024.05.pdf\n",
      "Frage 3: Welche Algorithmen eignen sich für die Suche in Vektordatenbanken?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:10:09,329 [INFO] HTTP Request: POST http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-04-16 12:10:29,290 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 4290\n",
      "Antwort: Eine Frage, die direkt zum Thema \"Algorithmen und Datenstrukturen\" passt!\n",
      "\n",
      "Die Suche in Vektordatenbanken ist ein klassisches Problem der Datenstrukturierung. Hier sind einige Algorithmen, die sich für diese Aufgabe eignen:\n",
      "\n",
      "1. **Bäume**: Bäume wie Binärsuche- oder AVL-Bäume können effizient zur Suche in Vektordatenbanken verwendet werden.\n",
      "2. **Hashing**: Hashfunktionen können verwendet werden, um die Daten schnell und effizient zu indexieren und zu suchen.\n",
      "3. **Suchalgorithmen für B-Treelike-Strukturen**: Algorithmen wie der B+-Tree oder der B*-Tree können zur Suche in großen Datenbanken eingesetzt werden.\n",
      "\n",
      "Es ist jedoch wichtig zu beachten, dass die Wahl des geeigneten Algorithmus von den spezifischen Anforderungen und Eigenschaften der Vektordatenbank abhängt.\n",
      "--------------------------------------------------\n",
      "Für weitere Informationen besuchen Sie:\n",
      "- https://www.fh-swf.de/media/neu_np/hv_2/dateien_sg_2_4/verlaufsplaene_modulhandbuecher_1/meschede_6/Modulhandbuch_BA_WFM_19_2024.05.pdf\n",
      "- https://www.fh-swf.de/media/neu_np/hv_2/dateien_sg_2_4/verlaufsplaene_modulhandbuecher_1/hagen/tbw_neu/Modulhandbuch_Winf_FPO_2018_Stand_09.2024.pdf\n",
      "Frage 4: Ist die FH morgen geschlossen?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:10:42,840 [INFO] HTTP Request: POST http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-04-16 12:11:02,587 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 4312\n",
      "Antwort: Die Öffnungszeiten der Fachhochschule Südwestfalen variieren je nach Standort. \n",
      "\n",
      "Für den Standort Iserlohn sind die Öffnungszeiten wie folgt:\n",
      "\n",
      "- Montags bis Freitags: 07:00 - 19:30 Uhr\n",
      "- Samstags (nur bei Präsenzterminen im Verbundstudium): 08:00 - 18:00 Uhr\n",
      "\n",
      "Für den Standort Meschede sind die Öffnungszeiten wie folgt:\n",
      "\n",
      "- Montags bis Freitags: 07:00 - 21:00 Uhr\n",
      "- Samstags (vorlesungsfreie Zeit): nur nach Bedarf\n",
      "\n",
      "Für den Standort Hagen sind die Öffnungszeiten wie folgt:\n",
      "\n",
      "- Montags bis Freitags: 07:00 - 21:00 Uhr, vorlesungsfreie Zeit: 07:00 - 20:00 Uhr\n",
      "- Samstags (vorlesungsfreie Zeit): nur nach Bedarf\n",
      "\n",
      "Es ist ratsam, sich an den jeweiligen Standort zu wenden, um die genauen Öffnungszeiten für morgen zu erfragen.\n",
      "--------------------------------------------------\n",
      "Für weitere Informationen besuchen Sie:\n",
      "- https://www.fh-swf.de/de/studienangebot/index.php\n",
      "- https://www.fh-swf.de/de/ueber_uns/standorte_4/iserlohn_4/iserlohn_1.php\n",
      "Frage 5: Welche Studiengänge werden an der Ruhr-Universität Bochum angeboten?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-16 12:11:18,859 [INFO] HTTP Request: POST http://localhost:6333/collections/mixedbread-ai_deepset-mxbai-embed-de-large-v1_recursive_chunks/points/query \"HTTP/1.1 200 OK\"\n",
      "2025-04-16 12:11:38,862 [INFO] HTTP Request: POST http://127.0.0.1:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Tokens: 4401\n",
      "Antwort: Das weiß ich leider nicht.\n",
      "--------------------------------------------------\n",
      "Für weitere Informationen besuchen Sie:\n",
      "- https://www.fh-swf.de/de/studienangebot/index.php\n",
      "- https://www.fh-swf.de/de/studienangebot/studiengaenge/index.php\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
